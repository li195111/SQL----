{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642334c7",
   "metadata": {},
   "source": [
    "PySpark SQL 零基礎入門教學 🎈\n",
    "=================================================\n",
    "\n",
    "這份教學會用最簡單的方式，教你如何使用 PySpark 來學習 SQL。\n",
    "想像 SQL 就像是和資料庫說話的魔法語言！✨\n",
    "\n",
    "作者：QChoice AI 教學團隊\n",
    "日期：2025-01-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1488b0",
   "metadata": {},
   "source": [
    "## 🎯 環境設定 - 準備開發環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f356ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# 創建 Spark Session - 就像打開一個魔法工作台\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SQL入門教學\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"🎉 歡迎學習 SQL！讓我們開始吧！\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6c981",
   "metadata": {},
   "source": [
    "## 📚 第一章：基礎查詢操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💪 練習題 1\n",
    "\n",
    "**題目：**\n",
    "\n",
    "請建立一個包含書籍資料的 DataFrame（包含：書名、作者、價格、出版年份），並使用 SELECT 查詢所有書籍的書名和價格\n",
    "\n",
    "**提示：使用 createDataFrame 和 select 方法**\n",
    "\n",
    "<details>\n",
    "<summary>📝 點擊查看參考答案</summary>\n",
    "\n",
    "```python\n",
    "# 建立書籍資料\n",
    "books_data = [\n",
    "    (\"Python 入門\", \"張三\", 450, 2023),\n",
    "    (\"資料科學實戰\", \"李四\", 680, 2024),\n",
    "    (\"SQL 精通\", \"王五\", 520, 2023),\n",
    "    (\"機器學習\", \"趙六\", 750, 2024)\n",
    "]\n",
    "\n",
    "books_df = spark.createDataFrame(books_data, [\"書名\", \"作者\", \"價格\", \"出版年份\"])\n",
    "\n",
    "# 方法 1: DataFrame API\n",
    "books_df.select(\"書名\", \"價格\").show()\n",
    "\n",
    "# 方法 2: SQL 語法\n",
    "books_df.createOrReplaceTempView(\"books\")\n",
    "spark.sql(\"SELECT 書名, 價格 FROM books\").show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💪 練習題 2\n",
    "\n",
    "**題目：**\n",
    "\n",
    "請在書籍資料表中新增 2 本新書\n",
    "\n",
    "**提示：建立新的 DataFrame 並使用 union 合併**\n",
    "\n",
    "<details>\n",
    "<summary>📝 點擊查看參考答案</summary>\n",
    "\n",
    "```python\n",
    "# 新書資料\n",
    "new_books = [\n",
    "    (\"深度學習\", \"錢七\", 820, 2024),\n",
    "    (\"大數據分析\", \"孫八\", 590, 2023)\n",
    "]\n",
    "\n",
    "new_books_df = spark.createDataFrame(new_books, [\"書名\", \"作者\", \"價格\", \"出版年份\"])\n",
    "\n",
    "# 合併資料\n",
    "books_df = books_df.union(new_books_df)\n",
    "books_df.show()\n",
    "\n",
    "print(f\"總書籍數: {books_df.count()}\")\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💪 練習題 3\n",
    "\n",
    "**題目：**\n",
    "\n",
    "請篩選出價格大於 600 元且出版年份為 2024 年的書籍\n",
    "\n",
    "**提示：使用 filter 或 where 方法，並使用多個條件**\n",
    "\n",
    "<details>\n",
    "<summary>📝 點擊查看參考答案</summary>\n",
    "\n",
    "```python\n",
    "# 方法 1: DataFrame API\n",
    "expensive_new_books = books_df.filter(\n",
    "    (col(\"價格\") > 600) & (col(\"出版年份\") == 2024)\n",
    ")\n",
    "expensive_new_books.show()\n",
    "\n",
    "# 方法 2: SQL 語法\n",
    "books_df.createOrReplaceTempView(\"books\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM books\n",
    "    WHERE 價格 > 600 AND 出版年份 = 2024\n",
    "    ORDER BY 價格 DESC\n",
    "\"\"\").show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ SELECT - 查詢資料（從資料表中取出你要的資料）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dc1c6b",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "SELECT 就像是你告訴媽媽「我想要看我的玩具」\n",
    "你可以選擇看全部的玩具，或只看特定的玩具\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，從玩具資料表中選取所有玩具的名稱和顏色，\n",
    "並顯示前5筆資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例資料：建立一個玩具清單\n",
    "toys_data = [\n",
    "    (1, \"小熊\", \"棕色\", 299),\n",
    "    (2, \"機器人\", \"藍色\", 599),\n",
    "    (3, \"芭比娃娃\", \"粉色\", 399),\n",
    "    (4, \"樂高\", \"彩色\", 899),\n",
    "    (5, \"小汽車\", \"紅色\", 199)\n",
    "]\n",
    "\n",
    "toys_df = spark.createDataFrame(toys_data, [\"id\", \"名稱\", \"顏色\", \"價格\"])\n",
    "\n",
    "# SQL 方式 1：使用 SQL 語法\n",
    "toys_df.createOrReplaceTempView(\"toys\")\n",
    "result = spark.sql(\"SELECT `名稱`, `顏色` FROM toys\")\n",
    "print(\"\\n📌 範例 1: SELECT - 選取玩具名稱和顏色\")\n",
    "result.show()\n",
    "\n",
    "# PySpark DataFrame 方式（另一種寫法）\n",
    "result2 = toys_df.select(\"名稱\", \"顏色\")\n",
    "print(\"📌 使用 DataFrame API 的結果：\")\n",
    "result2.show()\n",
    "\n",
    "\n",
    "# 2️⃣ INSERT - 新增資料（在資料表中加入新的記錄）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ce64e",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "INSERT 就像買了新玩具後，把它放進你的玩具箱\n",
    "資料庫會記住這個新玩具\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，將一個新玩具「泰迪熊」新增到玩具資料表中，\n",
    "顏色是「白色」，價格是 450 元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新玩具資料\n",
    "new_toy = [(6, \"泰迪熊\", \"白色\", 450)]\n",
    "new_toy_df = spark.createDataFrame(new_toy, [\"id\", \"名稱\", \"顏色\", \"價格\"])\n",
    "\n",
    "# 合併資料（模擬 INSERT）\n",
    "toys_df = toys_df.union(new_toy_df)\n",
    "toys_df.createOrReplaceTempView(\"toys\")\n",
    "\n",
    "print(\"\\n📌 範例 2: INSERT - 新增新玩具\")\n",
    "spark.sql(\"SELECT * FROM toys\").show()\n",
    "\n",
    "\n",
    "# 3️⃣ UPDATE - 更新資料（修改已存在的資料內容）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dd01e",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "UPDATE 就像你的玩具舊了，你幫它換個新顏色或修理一下\n",
    "在資料庫裡改變某個資料的內容\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，將玩具「小熊」的價格從 299 元更新為 350 元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark 沒有直接的 UPDATE，我們用 withColumn 和 when\n",
    "print(\"\\n📌 範例 3: UPDATE - 更新小熊的價格\")\n",
    "\n",
    "toys_df = toys_df.withColumn(\n",
    "    \"價格\",\n",
    "    when(col(\"名稱\") == \"小熊\", 350).otherwise(col(\"價格\"))\n",
    ")\n",
    "toys_df.createOrReplaceTempView(\"toys\")\n",
    "spark.sql(\"SELECT * FROM toys WHERE `名稱` = '小熊'\").show()\n",
    "\n",
    "\n",
    "# 4️⃣ DELETE - 刪除資料（移除不需要的記錄）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609d39c",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "DELETE 就像你決定把壞掉的玩具丟掉\n",
    "從資料庫移除不需要的資料\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，刪除價格低於 200 元的所有玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 4: DELETE - 刪除便宜的玩具\")\n",
    "\n",
    "# 使用 filter 保留價格 >= 200 的玩具\n",
    "toys_df = toys_df.filter(col(\"價格\") >= 200)\n",
    "toys_df.createOrReplaceTempView(\"toys\")\n",
    "spark.sql(\"SELECT * FROM toys\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2dbd7",
   "metadata": {},
   "source": [
    "## 📚 第二章：資料庫和資料表管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💪 練習題 4\n",
    "\n",
    "**題目：**\n",
    "\n",
    "請建立一個「員工」資料表，包含：員工編號、姓名、部門、薪資、入職日期\n",
    "\n",
    "**提示：使用 StructType 定義 schema**\n",
    "\n",
    "<details>\n",
    "<summary>📝 點擊查看參考答案</summary>\n",
    "\n",
    "```python\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "from datetime import date\n",
    "\n",
    "# 定義 schema\n",
    "employee_schema = StructType([\n",
    "    StructField(\"員工編號\", StringType(), False),\n",
    "    StructField(\"姓名\", StringType(), False),\n",
    "    StructField(\"部門\", StringType(), True),\n",
    "    StructField(\"薪資\", IntegerType(), True),\n",
    "    StructField(\"入職日期\", DateType(), True)\n",
    "])\n",
    "\n",
    "# 建立測試資料\n",
    "employees_data = [\n",
    "    (\"E001\", \"張三\", \"工程部\", 55000, date(2022, 1, 15)),\n",
    "    (\"E002\", \"李四\", \"業務部\", 48000, date(2023, 3, 20)),\n",
    "    (\"E003\", \"王五\", \"工程部\", 62000, date(2021, 6, 10))\n",
    "]\n",
    "\n",
    "# 建立 DataFrame\n",
    "employees_df = spark.createDataFrame(employees_data, employee_schema)\n",
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "employees_df.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💪 練習題 5\n",
    "\n",
    "**題目：**\n",
    "\n",
    "請為員工資料表新增一個「績效等級」欄位，並根據薪資自動分級（>=60000為A級，>=50000為B級，其他為C級）\n",
    "\n",
    "**提示：使用 withColumn 和 when 函數**\n",
    "\n",
    "<details>\n",
    "<summary>📝 點擊查看參考答案</summary>\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# 新增績效等級欄位\n",
    "employees_df = employees_df.withColumn(\n",
    "    \"績效等級\",\n",
    "    when(col(\"薪資\") >= 60000, \"A級\")\n",
    "    .when(col(\"薪資\") >= 50000, \"B級\")\n",
    "    .otherwise(\"C級\")\n",
    ")\n",
    "\n",
    "employees_df.show()\n",
    "\n",
    "# 統計各等級人數\n",
    "employees_df.groupBy(\"績效等級\").count().show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ CREATE DATABASE - 建立資料庫（蓋一個新的玩具倉庫）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c566f",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "CREATE DATABASE 就像蓋一個全新的倉庫來放你的東西\n",
    "一個大倉庫裡可以有很多小盒子（資料表）\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，建立一個名為「toy_warehouse」的資料庫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e430f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 5: CREATE DATABASE - 建立資料庫（概念說明）\")\n",
    "\n",
    "# 在 PySpark 中，我們不需要建立資料庫\n",
    "# 直接使用臨時視圖即可\n",
    "print(\"\"\"\n",
    "在標準 SQL 中：\n",
    "  CREATE DATABASE toy_warehouse\n",
    "\n",
    "在 PySpark 中：\n",
    "  使用臨時視圖來組織資料，不需要明確建立資料庫\n",
    "  臨時視圖會自動在 'default' 命名空間中\n",
    "  \n",
    "如果需要資料庫功能，可以：\n",
    "  1. 使用 Hive：設定 spark.sql.catalogImplementation=hive\n",
    "  2. 使用 Delta Lake：提供更強大的資料管理功能\n",
    "  3. 使用檔案系統：直接儲存為 Parquet/CSV 等格式\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ea29f",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "CREATE TABLE 就像準備一個有格子的盒子\n",
    "每個格子都有名字，知道要放什麼東西\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，建立一個「學生成績」資料表，\n",
    "包含學生姓名、科目、分數三個欄位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057357c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 6: CREATE TABLE - 建立資料表（使用 DataFrame）\")\n",
    "\n",
    "# 方法 1：使用 DataFrame 定義結構並建立臨時視圖\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "students_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"subject\", StringType(), True),\n",
    "    StructField(\"score\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# 建立空的 DataFrame 作為「資料表」\n",
    "students_df = spark.createDataFrame([], students_schema)\n",
    "students_df.createOrReplaceTempView(\"students\")\n",
    "\n",
    "print(\"✅ 已建立 students 臨時視圖（類似資料表）\")\n",
    "print(\"資料表結構：\")\n",
    "students_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf259f",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "DROP DATABASE 會刪除整個資料庫及其所有內容\n",
    "裡面的所有資料表都會被刪除，使用時需特別小心\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，刪除名為「old_warehouse」的資料庫。\n",
    "（注意：會刪除所有裡面的資料表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aea791",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 7: DROP DATABASE - 刪除資料庫（概念說明）\")\n",
    "\n",
    "# 在 PySpark 中，我們使用臨時視圖而非資料庫\n",
    "# 概念說明：\n",
    "print(\"\"\"\n",
    "在標準 SQL 中：\n",
    "  DROP DATABASE IF EXISTS old_warehouse\n",
    "\n",
    "在 PySpark 中：\n",
    "  使用臨時視圖（Temp Views）來組織資料\n",
    "  可以透過命名規則來模擬資料庫分組，例如：\n",
    "  - db1_table1\n",
    "  - db1_table2\n",
    "  - db2_table1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20c3ef",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "DROP TABLE 會刪除整個資料表\n",
    "資料庫仍然存在，只是移除了這個資料表\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，刪除「舊玩具」資料表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8341a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 8: DROP TABLE - 刪除資料表（使用 dropTempView）\")\n",
    "\n",
    "# 先建立一個測試用的臨時視圖\n",
    "test_data = [(1, \"舊玩具\")]\n",
    "test_df = spark.createDataFrame(test_data, [\"id\", \"name\"])\n",
    "test_df.createOrReplaceTempView(\"old_toys\")\n",
    "print(\"✅ 已建立 old_toys 臨時視圖\")\n",
    "\n",
    "# 刪除臨時視圖\n",
    "spark.catalog.dropTempView(\"old_toys\")\n",
    "print(\"✅ 已刪除 old_toys 臨時視圖\")\n",
    "\n",
    "# 驗證是否已刪除\n",
    "try:\n",
    "    spark.sql(\"SELECT * FROM old_toys\").show()\n",
    "except Exception as e:\n",
    "    print(f\"✅ 確認已刪除：{type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22b0e5",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "ALTER TABLE 可以新增欄位、修改欄位名稱或改變欄位型態\n",
    "常用於調整資料表結構\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，在玩具資料表中新增一個「製造商」欄位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d490804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 9: ALTER TABLE - 修改資料表結構\")\n",
    "\n",
    "# 新增欄位\n",
    "toys_df = toys_df.withColumn(\"製造商\", lit(\"快樂玩具公司\"))\n",
    "toys_df.createOrReplaceTempView(\"toys\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM toys LIMIT 3\").show()\n",
    "\n",
    "\n",
    "# 🔟 TRUNCATE TABLE - 清空資料表（把盒子裡的東西全倒掉）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146814fd",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "TRUNCATE TABLE 會清空資料表中的所有資料\n",
    "但資料表結構保留，只是沒有任何記錄\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，清空「暫存資料」資料表的所有內容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 10: TRUNCATE TABLE - 清空資料表\")\n",
    "\n",
    "# 建立空的 DataFrame（模擬 TRUNCATE）\n",
    "empty_df = spark.createDataFrame([], toys_df.schema)\n",
    "print(\"✅ 資料表已清空（保留結構）\")\n",
    "empty_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20336f52",
   "metadata": {},
   "source": [
    "## 📚 第三章：索引管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4049c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣1️⃣ CREATE INDEX - 建立索引（做一本目錄）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b8686d",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "CREATE INDEX 建立索引可以加快查詢速度\n",
    "想找東西的時候可以更快找到\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，在玩具資料表的「名稱」欄位上建立索引，\n",
    "以加快查詢速度。（說明：PySpark 使用 cache 來優化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3be57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 11: CREATE INDEX - 優化查詢速度\")\n",
    "\n",
    "# PySpark 使用 cache() 來優化常用查詢\n",
    "toys_df.cache()\n",
    "print(\"✅ 資料已快取，查詢會更快！\")\n",
    "\n",
    "\n",
    "# 1️⃣2️⃣ DROP INDEX - 刪除索引（把目錄撕掉）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0781c8a",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "DROP INDEX 刪除不需要的索引\n",
    "不會影響內容，只是找東西會慢一點\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，移除玩具資料表上的快取索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c226d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 12: DROP INDEX - 移除快取\")\n",
    "\n",
    "toys_df.unpersist()\n",
    "print(\"✅ 快取已移除\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd7bdc",
   "metadata": {},
   "source": [
    "## 📚 第四章：資料表連接（JOIN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💪 練習題 6\n",
    "\n",
    "**題目：**\n",
    "\n",
    "請建立「訂單」和「客戶」兩個資料表，然後使用 INNER JOIN 查詢所有訂單及其客戶資訊\n",
    "\n",
    "**提示：建立兩個 DataFrame，然後使用 join 方法**\n",
    "\n",
    "<details>\n",
    "<summary>📝 點擊查看參考答案</summary>\n",
    "\n",
    "```python\n",
    "# 建立客戶資料\n",
    "customers_data = [\n",
    "    (1, \"王小明\", \"台北市\"),\n",
    "    (2, \"李小華\", \"台中市\"),\n",
    "    (3, \"張小美\", \"高雄市\")\n",
    "]\n",
    "customers_df = spark.createDataFrame(customers_data, [\"客戶編號\", \"客戶姓名\", \"城市\"])\n",
    "\n",
    "# 建立訂單資料\n",
    "orders_data = [\n",
    "    (101, 1, \"2024-01-15\", 1500),\n",
    "    (102, 2, \"2024-01-16\", 2300),\n",
    "    (103, 1, \"2024-01-17\", 890),\n",
    "    (104, 3, \"2024-01-18\", 3200)\n",
    "]\n",
    "orders_df = spark.createDataFrame(orders_data, [\"訂單編號\", \"客戶編號\", \"訂單日期\", \"金額\"])\n",
    "\n",
    "# INNER JOIN\n",
    "result = orders_df.join(\n",
    "    customers_df,\n",
    "    orders_df[\"客戶編號\"] == customers_df[\"客戶編號\"],\n",
    "    \"inner\"\n",
    ").select(\n",
    "    orders_df[\"訂單編號\"],\n",
    "    orders_df[\"訂單日期\"],\n",
    "    customers_df[\"客戶姓名\"],\n",
    "    customers_df[\"城市\"],\n",
    "    orders_df[\"金額\"]\n",
    ")\n",
    "\n",
    "result.show()\n",
    "\n",
    "# 計算每個客戶的總消費\n",
    "customers_df.createOrReplaceTempView(\"customers\")\n",
    "orders_df.createOrReplaceTempView(\"orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.客戶姓名,\n",
    "        c.城市,\n",
    "        COUNT(o.訂單編號) as 訂單數,\n",
    "        SUM(o.金額) as 總消費\n",
    "    FROM customers c\n",
    "    INNER JOIN orders o ON c.客戶編號 = o.客戶編號\n",
    "    GROUP BY c.客戶姓名, c.城市\n",
    "    ORDER BY 總消費 DESC\n",
    "\"\"\").show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65487725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備範例資料：學生和成績\n",
    "students_data = [\n",
    "    (1, \"小明\", 10),\n",
    "    (2, \"小華\", 10),\n",
    "    (3, \"小美\", 11)\n",
    "]\n",
    "\n",
    "scores_data = [\n",
    "    (1, \"數學\", 85),\n",
    "    (2, \"數學\", 90),\n",
    "    (3, \"數學\", 88),\n",
    "    (4, \"數學\", 92)  # 這個學生不在學生表中\n",
    "]\n",
    "\n",
    "students_df = spark.createDataFrame(students_data, [\"id\", \"姓名\", \"年齡\"])\n",
    "scores_df = spark.createDataFrame(scores_data, [\"student_id\", \"科目\", \"分數\"])\n",
    "\n",
    "students_df.createOrReplaceTempView(\"students\")\n",
    "scores_df.createOrReplaceTempView(\"scores\")\n",
    "\n",
    "\n",
    "# 1️⃣3️⃣ INNER JOIN - 內部連接（只拿兩邊都有的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e82278",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "INNER JOIN 只保留兩個資料表都有匹配的記錄\n",
    "只有兩邊都有的才會被選出來\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，將學生資料表和成績資料表做 INNER JOIN，\n",
    "只顯示有成績記錄的學生資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 13: INNER JOIN - 兩邊都有的才留下\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4784c",
   "metadata": {},
   "source": [
    "SELECT s.姓名, sc.科目, sc.分數\n",
    "    FROM students s\n",
    "    INNER JOIN scores sc ON s.id = sc.student_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ace0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 1️⃣4️⃣ LEFT JOIN - 左連接（保留左邊全部）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ea0f7",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "LEFT JOIN 保留左表的所有記錄\n",
    "左邊的全部保留，右邊有配對的就加上，沒有就留空\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，顯示所有學生，即使他們沒有成績記錄也要顯示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 14: LEFT JOIN - 保留所有學生\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f40d0e",
   "metadata": {},
   "source": [
    "SELECT s.姓名, sc.科目, sc.分數\n",
    "    FROM students s\n",
    "    LEFT JOIN scores sc ON s.id = sc.student_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543aba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 1️⃣5️⃣ RIGHT JOIN - 右連接（保留右邊全部）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237bf4d",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "RIGHT JOIN 保留右表的所有記錄\n",
    "右邊的全部保留，左邊有配對的就加上\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，顯示所有成績記錄，\n",
    "即使某些成績找不到對應的學生也要顯示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95036e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 15: RIGHT JOIN - 保留所有成績\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e11f8d",
   "metadata": {},
   "source": [
    "SELECT s.姓名, sc.科目, sc.分數\n",
    "    FROM students s\n",
    "    RIGHT JOIN scores sc ON s.id = sc.student_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 1️⃣6️⃣ FULL OUTER JOIN - 全外部連接（兩邊都保留）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7234a",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "FULL OUTER JOIN 保留兩個資料表的所有記錄\n",
    "不管有沒有配對，全部都要！\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，顯示所有學生和所有成績記錄，\n",
    "不管是否有配對都要顯示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 16: FULL OUTER JOIN - 全部都要\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01134646",
   "metadata": {},
   "source": [
    "SELECT s.姓名, sc.科目, sc.分數\n",
    "    FROM students s\n",
    "    FULL OUTER JOIN scores sc ON s.id = sc.student_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c026a9",
   "metadata": {},
   "source": [
    "## 📚 第五章：集合操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備範例資料\n",
    "class_a = [(1, \"小明\"), (2, \"小華\"), (3, \"小美\")]\n",
    "class_b = [(3, \"小美\"), (4, \"小強\"), (5, \"小芳\")]\n",
    "\n",
    "class_a_df = spark.createDataFrame(class_a, [\"id\", \"姓名\"])\n",
    "class_b_df = spark.createDataFrame(class_b, [\"id\", \"姓名\"])\n",
    "\n",
    "\n",
    "# 1️⃣7️⃣ UNION - 聯集（把兩堆玩具合在一起，重複的只留一個）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a5d0d",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "UNION 合併兩個查詢結果\n",
    "如果有重複的人，只會記錄一次\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，合併 A 班和 B 班的學生名單，\n",
    "重複的學生只顯示一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 17: UNION - 合併並去除重複\")\n",
    "\n",
    "class_a_df.createOrReplaceTempView(\"class_a\")\n",
    "class_b_df.createOrReplaceTempView(\"class_b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c56aba",
   "metadata": {},
   "source": [
    "SELECT * FROM class_a\n",
    "    UNION\n",
    "    SELECT * FROM class_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 1️⃣8️⃣ UNION ALL - 全部聯集（重複的也保留）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded20601",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "UNION ALL 合併所有查詢結果\n",
    "就算有一樣的也不管，全部都要\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，合併兩個班級的點名記錄，\n",
    "包含所有重複的記錄。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 18: UNION ALL - 全部合併（含重複）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8827281",
   "metadata": {},
   "source": [
    "SELECT * FROM class_a\n",
    "    UNION ALL\n",
    "    SELECT * FROM class_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e6a17",
   "metadata": {},
   "source": [
    "## 📚 第六章：資料篩選與排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf09b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣9️⃣ DISTINCT - 去除重複（只留不一樣的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949a293",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "DISTINCT 去除重複的記錄\n",
    "重複的口味只拿一顆\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出玩具資料表中所有不同的顏色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 19: DISTINCT - 找出所有不同的顏色\")\n",
    "\n",
    "result = spark.sql(\"SELECT DISTINCT `顏色` FROM toys\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣0️⃣ WHERE - 條件篩選（只要符合條件的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568e230",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "WHERE 用來篩選符合條件的資料\n",
    "設定條件，只有符合的才能被選出來\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出價格大於 400 元的所有玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 20: WHERE - 篩選貴的玩具\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys WHERE `價格` > 400\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣1️⃣ ORDER BY - 排序（把東西排排站）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb567e",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "ORDER BY 用來排序查詢結果\n",
    "讓資料有順序\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，將所有玩具按照價格從高到低排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 21: ORDER BY - 價格排序\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys ORDER BY `價格` DESC\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣2️⃣ GROUP BY - 分組（把同類的放一起）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86544241",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "GROUP BY 將資料依指定欄位分組\n",
    "紅色的放一堆，藍色的放一堆\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，計算每種顏色有幾個玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e118a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 22: GROUP BY - 依顏色分組計數\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86520cea",
   "metadata": {},
   "source": [
    "SELECT 顏色, COUNT(*) as 數量\n",
    "    FROM toys\n",
    "    GROUP BY 顏色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣3️⃣ HAVING - 分組後篩選（分好組後再挑）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45552d4a",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "HAVING 用來篩選分組後的結果\n",
    "先分組，再選出符合條件的組\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出玩具數量大於 1 個的顏色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 23: HAVING - 篩選玩具數量多的顏色\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a063e5",
   "metadata": {},
   "source": [
    "SELECT 顏色, COUNT(*) as 數量\n",
    "    FROM toys\n",
    "    GROUP BY 顏色\n",
    "    HAVING COUNT(*) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e377f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9273ea",
   "metadata": {},
   "source": [
    "## 📚 第七章：聚合函數（統計運算）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣4️⃣ COUNT - 計數（數數看有幾個）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e60a77",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "COUNT 計算記錄的數量\n",
    "告訴你總共有幾個\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，計算玩具資料表中總共有幾個玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b349e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 24: COUNT - 數玩具總數\")\n",
    "\n",
    "result = spark.sql(\"SELECT COUNT(*) as `玩具總數` FROM toys\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣5️⃣ SUM - 總和（對指定欄位進行加總）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a49d7",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "SUM 計算數值欄位的總和\n",
    "算算看總共要花多少錢\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，計算所有玩具的總價值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 25: SUM - 計算總價值\")\n",
    "\n",
    "result = spark.sql(\"SELECT SUM(`價格`) as `總價值` FROM toys\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣6️⃣ AVG - 平均（算平均值）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a955bf",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "AVG 計算數值欄位的平均值\n",
    "所有價格加起來除以數量\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，計算玩具的平均價格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd65a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 26: AVG - 計算平均價格\")\n",
    "\n",
    "result = spark.sql(\"SELECT AVG(`價格`) as `平均價格` FROM toys\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣7️⃣ MIN - 最小值（找最小的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9c1e7",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "MIN 找出最小值\n",
    "看看哪個價格最低\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出價格最低的玩具價格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 27: MIN - 找最低價格\")\n",
    "\n",
    "result = spark.sql(\"SELECT MIN(`價格`) as `最低價格` FROM toys\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 2️⃣8️⃣ MAX - 最大值（找最大的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee8e6d",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "MAX 找出最大值\n",
    "看看哪個價格最高\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出價格最高的玩具及其價格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c286d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 28: MAX - 找最高價格\")\n",
    "\n",
    "result = spark.sql(\"SELECT MAX(`價格`) as `最高價格` FROM toys\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4c5ac",
   "metadata": {},
   "source": [
    "## 📚 第八章：條件與範圍查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96866f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣9️⃣ BETWEEN - 範圍查詢（在某個範圍內）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679db61",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "BETWEEN 用來查詢某個範圍內的資料\n",
    "找出在某個範圍內的東西\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出價格在 300 到 500 元之間的玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 29: BETWEEN - 找特定價格範圍的玩具\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys WHERE `價格` BETWEEN 300 AND 500\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣0️⃣ LIKE - 模糊搜尋（名字像什麼的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5ba9a",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "LIKE 用來進行模糊搜尋\n",
    "不用完全一樣，有包含就可以\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出名稱中包含「熊」字的所有玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 30: LIKE - 模糊搜尋玩具名稱\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys WHERE `名稱` LIKE '%熊%'\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣1️⃣ IN - 清單比對（在這些裡面的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3757b8",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "IN 檢查值是否在指定清單中\n",
    "只要在清單裡的都可以\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出顏色是「紅色」、「藍色」或「粉色」的玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a42334",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 31: IN - 找特定顏色的玩具\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys WHERE `顏色` IN ('紅色', '藍色', '粉色')\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣2️⃣ NOT - 否定（不要這個）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2bc16a",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "NOT 用來反轉條件\n",
    "把條件相反\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出顏色不是「棕色」的所有玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db628b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 32: NOT - 排除特定條件\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys WHERE NOT `顏色` = '棕色'\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣3️⃣ IS NULL - 檢查空值（有沒有遺失）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fcffea",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "IS NULL 檢查欄位是否為空值\n",
    "找出資料遺失的地方\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出沒有填寫顏色的玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8187aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 33: IS NULL - 找遺失資料\")\n",
    "\n",
    "# 先加一個沒有顏色的玩具\n",
    "toys_with_null = toys_df.union(\n",
    "    spark.createDataFrame([(7, \"神秘玩具\", None, 999, \"快樂玩具公司\")], \n",
    "                         toys_df.schema)\n",
    ")\n",
    "toys_with_null.createOrReplaceTempView(\"toys_with_null\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys_with_null WHERE `顏色` IS NULL\")\n",
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣4️⃣ IS NOT NULL - 檢查非空值（有資料的）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6316ee86",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "IS NOT NULL 檢查欄位是否有值\n",
    "找出有完整資訊的\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出所有有填寫顏色的玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 34: IS NOT NULL - 找完整資料\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM toys_with_null WHERE `顏色` IS NOT NULL\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef96f4",
   "metadata": {},
   "source": [
    "## 📚 第九章：進階條件邏輯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣5️⃣ CASE - 條件判斷（如果...那麼...）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f456a4b",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "CASE 根據不同條件回傳不同的值\n",
    "根據不同情況給不同答案\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，依據價格將玩具分為「昂貴」（>500）、\n",
    "「中等」（300-500）、「便宜」（<300）三個等級。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf26f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 35: CASE - 價格等級分類\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08d19b",
   "metadata": {},
   "source": [
    "SELECT 名稱, 價格,\n",
    "        CASE \n",
    "            WHEN 價格 > 500 THEN '昂貴'\n",
    "            WHEN 價格 >= 300 THEN '中等'\n",
    "            ELSE '便宜'\n",
    "        END as 價格等級\n",
    "    FROM toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣6️⃣ COALESCE - 取第一個非空值（找替代方案）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334d6ee",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "COALESCE 回傳第一個非 NULL 的值\n",
    "找第一個不是空的值\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，如果玩具沒有顏色資訊，就顯示「未知」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 36: COALESCE - 處理空值\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aec449",
   "metadata": {},
   "source": [
    "SELECT 名稱, COALESCE(顏色, '未知') as 顏色\n",
    "    FROM toys_with_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c1ff0b",
   "metadata": {},
   "source": [
    "## 📚 第十章：子查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣7️⃣ EXISTS - 存在檢查（有沒有這個東西）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22472308",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "EXISTS 檢查子查詢是否有結果\n",
    "檢查是否存在符合條件的資料\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出有昂貴玩具（>500元）的製造商。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 37: EXISTS - 檢查是否存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12831a8b",
   "metadata": {},
   "source": [
    "SELECT DISTINCT 製造商\n",
    "    FROM toys t1\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 FROM toys t2 \n",
    "        WHERE t2.製造商 = t1.製造商 AND t2.價格 > 500\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30721ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣8️⃣ ANY/SOME - 任一比對（只要有一個符合）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff02c8d",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "ANY/SOME 與子查詢的任一值比較\n",
    "和一堆值比較，有一個符合就可以\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出價格比任一藍色玩具還貴的玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 38: ANY/SOME - 任一比對\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c26e80",
   "metadata": {},
   "source": [
    "SELECT 名稱, 價格\n",
    "    FROM toys\n",
    "    WHERE 價格 > ANY (SELECT 價格 FROM toys WHERE 顏色 = '藍色')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 3️⃣9️⃣ ALL - 全部比對（要全部都符合）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bebabc",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "ALL 與子查詢的所有值比較\n",
    "和一堆值比較，全部都要符合\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，找出價格比所有藍色玩具都貴的玩具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 39: ALL - 全部比對\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bfa94",
   "metadata": {},
   "source": [
    "SELECT 名稱, 價格\n",
    "    FROM toys\n",
    "    WHERE 價格 > ALL (SELECT 價格 FROM toys WHERE 顏色 = '藍色')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()\n",
    "\n",
    "\n",
    "# 4️⃣0️⃣ JOIN - 一般連接（把兩個表格接起來）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30910295",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "JOIN 將兩個資料表連接起來\n",
    "找到相同的地方連接起來\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，將玩具表和製造商詳細資料表連接，\n",
    "顯示玩具名稱和製造商地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 40: JOIN - 連接兩個表格\")\n",
    "\n",
    "# 建立製造商資料\n",
    "manufacturers = [(1, \"快樂玩具公司\", \"台北市\")]\n",
    "manufacturers_df = spark.createDataFrame(\n",
    "    manufacturers, [\"id\", \"公司名稱\", \"地址\"]\n",
    ")\n",
    "manufacturers_df.createOrReplaceTempView(\"manufacturers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274babb",
   "metadata": {},
   "source": [
    "SELECT t.名稱, m.公司名稱, m.地址\n",
    "    FROM toys t\n",
    "    JOIN manufacturers m ON t.製造商 = m.公司名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd41901",
   "metadata": {},
   "source": [
    "## 📚 第十一章：資料表約束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣1️⃣ PRIMARY KEY - 主鍵（每個玩具的身份證）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2451b",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "PRIMARY KEY 唯一識別每一筆記錄的欄位\n",
    "確保每個資料都有獨一無二的識別碼\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，建立一個玩具資料表，\n",
    "以 id 作為主鍵（唯一識別碼）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2051027",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 41: PRIMARY KEY - 設定主鍵\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b75da",
   "metadata": {},
   "source": [
    "CREATE TABLE IF NOT EXISTS toys_pk (\n",
    "        id INT NOT NULL,\n",
    "        name STRING,\n",
    "        PRIMARY KEY (id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f824c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ 已建立帶主鍵的資料表\")\n",
    "\n",
    "\n",
    "# 4️⃣2️⃣ FOREIGN KEY - 外鍵（連結到另一個表格）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94dfc15",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "FOREIGN KEY 確保參照的資料存在於另一個資料表中\n",
    "確保資料之間有正確的關聯\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，建立訂單資料表，\n",
    "其中客戶 ID 是外鍵，必須參照客戶資料表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b03eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 42: FOREIGN KEY - 設定外鍵關聯\")\n",
    "\n",
    "# PySpark SQL 語法示範（實際執行可能因版本而異）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f70067",
   "metadata": {},
   "source": [
    "SQL 範例：\n",
    "CREATE TABLE orders (\n",
    "    order_id INT,\n",
    "    customer_id INT,\n",
    "    FOREIGN KEY (customer_id) REFERENCES customers(id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eaa445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣3️⃣ CONSTRAINT - 約束條件（設定規則）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb4d9f",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "CONSTRAINT 定義資料表的限制條件\n",
    "給資料設定必須遵守的規則\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，建立玩具資料表，\n",
    "並設定價格必須大於 0 的約束條件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 43: CONSTRAINT - 設定約束條件\")\n",
    "\n",
    "# 使用 DataFrame API 驗證\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 驗證價格都大於 0\n",
    "valid_toys = toys_df.filter(col(\"價格\") > 0)\n",
    "print(f\"✅ 驗證通過，所有玩具價格都大於 0\")\n",
    "valid_toys.select(\"名稱\", \"價格\").show(3)\n",
    "\n",
    "\n",
    "# 4️⃣4️⃣ INDEX - 索引優化（加快搜尋速度）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511de664",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "INDEX 加快資料查詢的速度\n",
    "可以快速找到想要的資料\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，對常查詢的欄位建立索引以提升效能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 44: INDEX - 效能優化\")\n",
    "\n",
    "# PySpark 使用分區和快取來優化\n",
    "toys_df.repartition(\"顏色\").cache()\n",
    "print(\"✅ 已按顏色分區並快取資料\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b37db",
   "metadata": {},
   "source": [
    "## 📚 第十二章：交易控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ecdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣5️⃣ TRANSACTION - 交易（一起做完或一起取消）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fba0e3",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "TRANSACTION 確保一系列操作要嘛全部成功，要嘛全部失敗\n",
    "確保多個操作要一起成功或一起失敗\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式說明交易的概念，\n",
    "將多個操作包在一個交易中執行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1513ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 45: TRANSACTION - 交易控制\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12795dc8",
   "metadata": {},
   "source": [
    "交易概念說明：\n",
    "想像你要買 3 個玩具，但錢只夠買 3 個\n",
    "如果其中一個賣完了，那就全部都不買\n",
    "這樣才不會只買到一部分玩具\n",
    "\n",
    "PySpark 中交易通常在寫入資料庫時使用：\n",
    "- 開始交易 (BEGIN)\n",
    "- 執行多個操作\n",
    "- 全部成功就提交 (COMMIT)\n",
    "- 有錯誤就回滾 (ROLLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣6️⃣ COMMIT - 提交（確定要存檔）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6f244",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "COMMIT 永久保存所有變更\n",
    "確定要把改變永久保存\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，示範如何在完成所有操作後提交交易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fec2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 46: COMMIT - 提交變更\")\n",
    "\n",
    "# 模擬交易提交\n",
    "try:\n",
    "    # 執行操作\n",
    "    new_data = [(8, \"新玩具\", \"黃色\", 350, \"快樂玩具公司\")]\n",
    "    new_df = spark.createDataFrame(new_data, toys_df.schema)\n",
    "    \n",
    "    # 寫入資料（模擬 COMMIT）\n",
    "    updated_toys = toys_df.union(new_df)\n",
    "    print(\"✅ 交易已提交，新玩具已加入\")\n",
    "    updated_toys.select(\"名稱\", \"價格\").tail(3)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 發生錯誤，交易回滾: {e}\")\n",
    "\n",
    "\n",
    "# 4️⃣7️⃣ ROLLBACK - 回滾（取消不要存檔）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0eaf55",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "ROLLBACK 取消尚未提交的變更\n",
    "回復到交易開始前的狀態\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，示範當發生錯誤時如何回滾交易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 47: ROLLBACK - 回滾交易\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0401f19",
   "metadata": {},
   "source": [
    "回滾範例：\n",
    "假設你不小心刪掉了重要資料\n",
    "ROLLBACK 可以讓你回到刪除之前的狀態\n",
    "還原所有未提交的操作\n",
    "\n",
    "在 PySpark 中：\n",
    "- 可以使用 checkpoint 保存檢查點\n",
    "- 發生錯誤時可以讀取檢查點資料\n",
    "- 恢復到之前的狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcae428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣8️⃣ SAVEPOINT - 儲存點（設定中途存檔點）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba5afb",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "SAVEPOINT 在交易中設定中途檢查點\n",
    "可以選擇回滾到特定的儲存點\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，示範如何在交易中設定多個儲存點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9606362",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 48: SAVEPOINT - 儲存點概念（使用快照替代）\")\n",
    "\n",
    "# 在 PySpark 中，我們使用變數保存不同階段的 DataFrame\n",
    "# 這類似於設定多個「儲存點」\n",
    "\n",
    "# 儲存點 1：原始資料\n",
    "savepoint_1 = toys_df\n",
    "print(\"✅ 儲存點 1：原始玩具資料\")\n",
    "print(f\"   記錄數：{savepoint_1.count()}\")\n",
    "\n",
    "# 執行一些操作\n",
    "filtered_df = toys_df.filter(col(\"價格\") > 300)\n",
    "\n",
    "# 儲存點 2：過濾後的資料\n",
    "savepoint_2 = filtered_df\n",
    "print(\"✅ 儲存點 2：過濾後的資料\")\n",
    "print(f\"   記錄數：{savepoint_2.count()}\")\n",
    "\n",
    "# 如果需要回到某個儲存點，直接使用該變數\n",
    "print(\"\\n💡 回到儲存點 1：\")\n",
    "savepoint_1.show(3)\n",
    "\n",
    "print(\"\"\"\n",
    "在傳統 SQL 中：\n",
    "  SAVEPOINT sp1;\n",
    "  -- 執行操作\n",
    "  SAVEPOINT sp2;\n",
    "  -- 可以 ROLLBACK TO sp1;\n",
    "\n",
    "在 PySpark 中：\n",
    "  使用變數保存不同階段的 DataFrame\n",
    "  或使用 Delta Lake 的時間旅行功能\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd401ab",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "GRANT 授予使用者特定的操作權限\n",
    "控制誰可以存取資料\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，授予使用者查詢玩具資料表的權限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f150d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 49: GRANT - 授予權限\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cd250",
   "metadata": {},
   "source": [
    "權限授予範例：\n",
    "\n",
    "-- 讓 user1 可以查詢玩具表\n",
    "GRANT SELECT ON toys TO user1;\n",
    "\n",
    "-- 讓 user2 可以新增玩具\n",
    "GRANT INSERT ON toys TO user2;\n",
    "\n",
    "-- 讓 admin 擁有所有權限\n",
    "GRANT ALL ON toys TO admin;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣0️⃣ REVOKE - 撤銷權限（收回鑰匙）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29098c52",
   "metadata": {},
   "source": [
    "🎈 概念解釋：\n",
    "REVOKE 撤銷使用者的權限\n",
    "移除已授予的存取權限\n",
    "\n",
    "🎯 AI Prompt 範例：\n",
    "請幫我寫一個 PySpark 程式，撤銷使用者對玩具資料表的刪除權限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📌 範例 50: REVOKE - 撤銷權限\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee94fc",
   "metadata": {},
   "source": [
    "權限撤銷範例：\n",
    "\n",
    "-- 不讓 user1 刪除玩具\n",
    "REVOKE DELETE ON toys FROM user1;\n",
    "\n",
    "-- 收回 user2 的所有權限\n",
    "REVOKE ALL ON toys FROM user2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎓 課程總結\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎊 恭喜！你已經完成了 SQL 的 50 個重要觀念！\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c62189",
   "metadata": {},
   "source": [
    "📝 學習總結：\n",
    "\n",
    "1️⃣ 基礎操作：SELECT, INSERT, UPDATE, DELETE\n",
    "   - 這些是最常用的基本操作\n",
    "\n",
    "2️⃣ 資料表管理：CREATE, DROP, ALTER, TRUNCATE\n",
    "   - 管理資料庫結構\n",
    "\n",
    "3️⃣ 連接操作：INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL OUTER JOIN\n",
    "   - 連接多個資料表\n",
    "\n",
    "4️⃣ 資料篩選：WHERE, HAVING, DISTINCT, ORDER BY, GROUP BY\n",
    "   - 篩選和排序資料\n",
    "\n",
    "5️⃣ 聚合函數：COUNT, SUM, AVG, MIN, MAX\n",
    "   - 執行統計運算\n",
    "\n",
    "6️⃣ 進階查詢：CASE, EXISTS, ANY, ALL, BETWEEN, LIKE, IN\n",
    "   - 進階的查詢技巧\n",
    "\n",
    "7️⃣ 交易控制：TRANSACTION, COMMIT, ROLLBACK, SAVEPOINT\n",
    "   - 維護資料一致性\n",
    "\n",
    "8️⃣ 權限管理：GRANT, REVOKE\n",
    "   - 管理使用者權限\n",
    "\n",
    "💡 學習建議：\n",
    "- 每個概念都要實際練習\n",
    "- 嘗試用真實的資料練習\n",
    "- 遇到問題可以尋求協助\n",
    "- 循序漸進地學習\n",
    "\n",
    "🚀 下一步：\n",
    "- 練習組合多個 SQL 語句\n",
    "- 應用於實際案例\n",
    "- 深入學習進階功能\n",
    "\n",
    "記住：熟能生巧，多練習就能掌握 SQL！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"📚 教學文件結束 - 祝你學習愉快！🎈\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 關閉 Spark Session\n",
    "# spark.stop()  # 取消註解以關閉 Spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fju",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}