# PySpark SQL 進階教學說明

## 📚 教學檔案

本進階教學包含兩個檔案：
- `2025_pyspark_sql_advanced.py` - Python 腳本格式
- `2025_pyspark_sql_advanced.ipynb` - Jupyter Notebook 格式

## 🎯 適用對象

- 已完成 SQL 基礎課程的學習者
- 熟悉基本的 SELECT、JOIN、GROUP BY 等語法
- 想要提升 SQL 技能到進階水平
- 需要處理大規模資料或效能優化的開發者

## 📖 課程大綱

### 第一章：視窗函數 (Window Functions)
1. **ROW_NUMBER** - 為每一列分配唯一的序號
2. **RANK & DENSE_RANK** - 處理並列排名
3. **LEAD & LAG** - 訪問前後列的資料（時間序列分析）
4. **累計計算** - SUM/AVG OVER（累計銷售額、移動平均）

### 第二章：通用表表達式 (CTE)
5. **WITH 子句** - 建立臨時結果集
6. **多層 CTE** - 複雜業務邏輯（客戶分級分析）

### 第三章：子查詢優化
7. **相關子查詢 vs 非相關子查詢** - 效能比較與優化策略

### 第四章：進階 JOIN 技巧
8. **CROSS JOIN** - 笛卡爾積應用
9. **SELF JOIN** - 自我連接（員工-主管關係）
10. **ANTI JOIN & SEMI JOIN** - 高效過濾

### 第五章：效能優化技巧
11. **Broadcast Join** - 廣播小表優化
12. **分區與分桶** - 資料組織優化
13. **快取與持久化** - 避免重複計算

### 第六章：複雜資料轉換
14. **PIVOT** - 行轉列（資料透視表）
15. **UNPIVOT** - 列轉行（資料正規化）
16. **陣列與結構處理** - 複雜資料型態操作

### 第七章：資料品質與清理
17. **處理 NULL 值** - fillna、dropna、coalesce
18. **資料去重** - distinct、dropDuplicates、視窗函數

### 第八章：進階分析函數
19. **NTILE** - 資料分組（四分位數、ABC 分析）
20. **PERCENT_RANK** - 百分位排名

## 💡 學習重點

### 視窗函數的核心概念
- 理解 PARTITION BY 和 ORDER BY 的作用
- 掌握不同視窗邊界的定義（ROWS BETWEEN）
- 學會選擇合適的視窗函數解決問題

### 效能優化策略
- 了解何時使用 Broadcast Join
- 掌握資料分區的最佳實踐
- 學會使用 Spark UI 分析效能瓶頸

### 實際應用場景
- 排名與 Top N 查詢
- 時間序列分析（同比、環比）
- 客戶分群與 RFM 分析
- 資料品質檢查與清理

## 🚀 實踐建議

1. **循序漸進**
   - 先理解每個範例的業務場景
   - 再學習對應的 SQL 語法
   - 最後動手實作並修改參數

2. **對比學習**
   - 比較不同方法的優劣（如相關子查詢 vs JOIN）
   - 測試不同參數的影響
   - 觀察執行計畫的差異

3. **實際專案應用**
   - 用進階技巧重構現有查詢
   - 解決實際的效能問題
   - 建立可重用的查詢模板

4. **效能測試**
   - 使用較大的測試資料集
   - 測量不同方法的執行時間
   - 分析 Spark UI 的執行計畫

## 📊 範例資料說明

教學中使用的範例資料包括：
- **員工資料**：姓名、部門、薪資（用於排名、分組分析）
- **考試成績**：學生、分數（用於排名比較）
- **月度銷售**：月份、銷售額（用於時間序列分析）
- **訂單資料**：客戶、日期、金額（用於 CTE、客戶分析）

所有範例資料都是精心設計的小型資料集，便於理解概念。實際應用時可以替換為真實資料。

## 🔧 環境需求

- Python 3.7+
- PySpark 3.0+
- Jupyter Notebook（可選）
- 建議記憶體：4GB+

## 📝 延伸學習資源

完成本課程後，建議繼續學習：
1. **Spark 效能調校**
   - Shuffle 優化
   - 記憶體管理
   - 資料傾斜處理

2. **Delta Lake**
   - ACID 交易
   - 時間旅行
   - Schema Evolution

3. **Spark Streaming**
   - 結構化串流
   - 即時資料處理
   - 視窗操作

4. **機器學習**
   - Spark MLlib
   - 特徵工程
   - 模型訓練與評估

## 💬 學習交流

遇到問題時：
1. 仔細閱讀錯誤訊息
2. 檢查資料型態和欄位名稱
3. 查看 Spark UI 的執行計畫
4. 使用 AI 助手（如範例中的 AI Prompt）
5. 參考官方文件和社群討論

## 🎓 學習成果檢驗

完成本課程後，你應該能夠：
- ✅ 使用視窗函數解決排名、累計、移動平均等問題
- ✅ 用 CTE 重構複雜的多層查詢
- ✅ 選擇合適的 JOIN 類型並進行效能優化
- ✅ 處理複雜的資料轉換（PIVOT、陣列操作等）
- ✅ 進行基本的 Spark 效能調校
- ✅ 建立資料品質檢查流程

祝你學習順利！🚀
